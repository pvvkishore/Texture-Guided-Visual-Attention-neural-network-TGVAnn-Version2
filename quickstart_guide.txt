# TGVAnn Quick Start Guide

Get started with TGVAnn in 5 minutes!

## Prerequisites

- Python 3.8+
- CUDA-capable GPU (recommended, 8GB+ VRAM)
- 10GB+ free disk space

## Installation (2 minutes)

```bash
# Clone repository
git clone https://github.com/pvvkishore/Texture-Feature-Guided-Attention-based-Fusion-AIA-Mar30-2025.git
cd Texture-Feature-Guided-Attention-based-Fusion-AIA-Mar30-2025

# Create environment
conda create -n tgvann python=3.9 -y
conda activate tgvann

# Install dependencies
pip install -r requirements.txt
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

## Dataset Setup (1 minute)

```bash
# Organize your RGB dataset
Maize_RGB/
â”œâ”€â”€ Class1/
â”‚   â”œâ”€â”€ img1.jpg
â”‚   â””â”€â”€ img2.jpg
â”œâ”€â”€ Class2/
â””â”€â”€ Class3/

# Generate texture features
python data/ldp_texture_generator.py
# This creates Maize_Texture/ automatically
```

## Train Your First Model (30 seconds to start)

```bash
# Quick training (5 epochs for testing)
python train.py \
    --rgb_dir ./Maize_RGB \
    --texture_dir ./Maize_Texture \
    --output_dir ./outputs/quick_test \
    --batch_size 32 \
    --epochs 5 \
    --lr 1e-4 \
    --augment

# Full training (50 epochs for paper results)
python train.py \
    --rgb_dir ./Maize_RGB \
    --texture_dir ./Maize_Texture \
    --output_dir ./outputs/full_training \
    --batch_size 32 \
    --epochs 50 \
    --lr 1e-4 \
    --augment
```

## Evaluate Model (10 seconds)

```bash
python evaluate.py \
    --rgb_dir ./Maize_RGB \
    --texture_dir ./Maize_Texture \
    --checkpoint ./outputs/quick_test/best_model.pth \
    --output_dir ./eval_results
```

## Visualize Results (20 seconds)

```bash
python visualize_gradcam.py \
    --rgb_dir ./Maize_RGB \
    --texture_dir ./Maize_Texture \
    --checkpoint ./outputs/quick_test/best_model.pth \
    --output_dir ./gradcam_results \
    --mode both \
    --num_samples 16
```

## Check Model Statistics

```bash
python compute_model_stats.py
```

## Complete Workflow Example

```bash
# Run the complete end-to-end example
python example_complete_workflow.py
```

This will:
1. âœ… Generate texture features
2. âœ… Create TGVAnn model
3. âœ… Prepare data loaders
4. âœ… Train for 5 epochs
5. âœ… Evaluate performance

## Expected Output

After running the quick test, you should see:

```
Training complete!
Best Validation Accuracy: ~XX.XX%

Outputs:
./outputs/quick_test/
â”œâ”€â”€ best_model.pth          # Best model checkpoint
â”œâ”€â”€ final_model.pth         # Final epoch model
â”œâ”€â”€ training_history.png    # Loss and accuracy curves
â””â”€â”€ checkpoint_epoch_*.pth  # Periodic checkpoints

./eval_results/
â”œâ”€â”€ confusion_matrix.png    # Confusion matrix visualization
â””â”€â”€ evaluation_results.txt  # Detailed metrics

./gradcam_results/
â””â”€â”€ gradcam_visualization.png  # Attention heatmaps
```

## Troubleshooting

### Out of Memory
```bash
# Reduce batch size
python train.py ... --batch_size 16

# Or reduce input size
python train.py ... --input_size 224 --batch_size 32
```

### Missing THOP (for FLOPs calculation)
```bash
pip install thop
```

### Slow Training
```bash
# Use fewer workers if CPU limited
python train.py ... --num_workers 2

# Or increase batch size if GPU memory allows
python train.py ... --batch_size 64
```

## Next Steps

1. **Improve Accuracy**: Train for more epochs (50-100)
2. **Hyperparameter Tuning**: Try different learning rates (1e-3, 1e-5)
3. **Data Augmentation**: Experiment with augmentation strength
4. **Visualize Attention**: Analyze Grad-CAM for model interpretability

## Folder Structure

```
TGVAnn/
â”œâ”€â”€ models/                 # Model architectures
â”œâ”€â”€ data/                   # Data processing
â”œâ”€â”€ train.py               # Training script
â”œâ”€â”€ evaluate.py            # Evaluation script
â”œâ”€â”€ visualize_gradcam.py   # Visualization
â”œâ”€â”€ compute_model_stats.py # Model analysis
â”œâ”€â”€ example_complete_workflow.py  # Full example
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ README.md             # Full documentation
â”œâ”€â”€ QUICKSTART.md         # This file
â””â”€â”€ ARCHITECTURE.md       # Architecture details
```

## Common Use Cases

### 1. Transfer Learning
```python
from models import TGVAnn

# Load pretrained weights
model = TGVAnn(num_classes=5)  # Your dataset classes
checkpoint = torch.load('best_model.pth')
model.load_state_dict(checkpoint['model_state_dict'])

# Fine-tune on new dataset
# ... your training code
```

### 2. Inference on Single Image
```python
import torch
from PIL import Image
from torchvision import transforms
from models import TGVAnn

# Load model
model = TGVAnn(num_classes=3)
checkpoint = torch.load('best_model.pth')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Prepare image
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

rgb_img = Image.open('test_image.jpg')
rgb_tensor = transform(rgb_img).unsqueeze(0)

# Load corresponding texture
texture_img = Image.open('test_texture.jpg').convert('L')
texture_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])
texture_tensor = texture_transform(texture_img).unsqueeze(0)

# Predict
with torch.no_grad():
    output, attention = model(rgb_tensor, texture_tensor)
    prediction = output.argmax(dim=1)
    
print(f"Predicted class: {prediction.item()}")
```

### 3. Custom Dataset
```python
# Prepare your dataset in ImageFolder format
Your_Dataset/
â”œâ”€â”€ RGB/
â”‚   â”œâ”€â”€ class1/
â”‚   â””â”€â”€ class2/
â””â”€â”€ Texture/  # Generated from RGB

# Train
python train.py \
    --rgb_dir ./Your_Dataset/RGB \
    --texture_dir ./Your_Dataset/Texture \
    --output_dir ./outputs/custom
```

## Performance Tips

1. **GPU Utilization**: Use `nvidia-smi` to monitor GPU usage
2. **Batch Size**: Larger = faster training but needs more memory
3. **Learning Rate**: Start with 1e-4, adjust if loss plateaus
4. **Epochs**: Monitor validation accuracy, stop if plateauing
5. **Data Augmentation**: Always enable for small datasets

## Support

- **Issues**: GitHub Issues
- **Email**: pvvkishore@example.com
- **Documentation**: See README.md and ARCHITECTURE.md

---

**That's it! You're ready to use TGVAnn for crop disease detection! ðŸŒ±**